{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Engineering\n",
    "\n",
    "In part 2 of software engineering practices, you'll learn about the following practices of software engineering and how they apply in data science.\n",
    "\n",
    "* Testing\n",
    "* Logging\n",
    "* Code reviews\n",
    "\n",
    "![code](images/code-robust.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Testing your code is essential before deployment. It helps you catch errors and faulty conclusions before they make any major impact. Today, employers are looking for data scientists with the skills to properly prepare their code for an industry setting, which includes testing their code.\n",
    "\n",
    "### Typical Errors on Data Science process\n",
    "* Bad encoding\n",
    "* Inappropriate features - the way that the features are used does not correspond to reality.\n",
    "* Unexpected features - data that break the model assumptions\n",
    "\n",
    "> These errors are more difficult to find, because we have to check the quality of the analysis in addidtion to the quality of the code. Therefore: **TESTING**\n",
    "\n",
    "* Problems that could occur in data science aren’t always easily detectable; you might have values being encoded incorrectly, features being used inappropriately, or unexpected data breaking assumptions.\n",
    "* To catch these errors, you have to check for the quality and accuracy of your analysis in addition to the quality of your code. Proper testing is necessary to avoid unexpected surprises and have confidence in your results.\n",
    "* Test-driven development (TDD): A development process in which you write tests for tasks before you even write the code to implement those tasks.\n",
    "* Unit test: A type of test that covers a “unit” of code—usually a single function—independently from the rest of the program.\n",
    "\n",
    "### Unit tests\n",
    "We want to test our functions in a way that is repeatable and automated. Ideally, we'd run a test program that runs all our unit tests and cleanly lets us know which ones failed and which ones succeeded.\n",
    "\n",
    "#### Example: nearest.py\n",
    "\n",
    "```python\n",
    "def nearest_square(num):\n",
    "\"\"\" Return the nearest perfect square that is less than or equal to num.\"\"\"\n",
    "root = 0; \n",
    "while (root + 1) ** 2 <= num:\n",
    "root +=1\n",
    "return root ** 2\n",
    "```\n",
    "\n",
    "**Interactive testing of nearest.py**\n",
    "\n",
    "```python\n",
    "from nearest import nearest_square\n",
    "nearest_square(5)\n",
    "nearest_square(-12)\n",
    "nearest_square(9)\n",
    "```\n",
    "\n",
    "**Putting code into a file to make it repeatable:**\n",
    "```python\n",
    "from nearest import nearest_square\n",
    "print(“Nearest square <= 5: nearest_square(5))\n",
    "print(“Nearest square <= -12: nearest_square(-12))\n",
    "print(“Nearest square <= 9: nearest_square(9))\n",
    "print(“Nearest square <= 23: nearest_square(23))\n",
    "```\n",
    "**Improving the file:**\n",
    "```python\n",
    "from nearest import nearest_square\n",
    "print(“Nearest square <= 5: returned {}, correct answer is 4.”.format(nearest_square(5)))\n",
    "print(“Nearest square <= -12: returned {}, correct answer is 0.”.format(nearest_square(-12)))\n",
    "print(“Nearest square <= 9: returned {}, correct answer is 9.”.format(nearest_square(9)))\n",
    "print(“Nearest square <= 23: returned {}, correct answer is 16.”.format(nearest_square(23)))\n",
    "```\n",
    "**Using assert:**\n",
    "```python\n",
    "from nearest import nearest_square\n",
    "nearest_5 = nearest_square(5)\n",
    "print(“Nearest square <= 5: returned {}, correct answer is 4.”.format(nearest_5))\n",
    "assert(nearest_5 == 4)\n",
    "nearest_n12 = nearest_square(-12)\n",
    "print(“Nearest square <= -12: returned {}, correct answer is 0.”.format(nearest_n12))\n",
    "assert(nearest_n12 == 0)\n",
    "nearest_9 = nearest_square(9)\n",
    "print(“Nearest square <= 9: returned {}, correct answer is 9.”.format(nearest_9))\n",
    "assert(nearest_9 == 9)\n",
    "nearest_23 = nearest_square(23)\n",
    "print(“Nearest square <= 23: returned {}, correct answer is 16.”.format(nearest_23))\n",
    "assert(nearest_23 == 16)\n",
    "```\n",
    "#### Unit test advantages and disadvantages\n",
    "The advantage of unit tests is that they are isolated from the rest of your program, and thus, no dependencies are involved. They don't require access to databases, APIs, or other external sources of information. However, passing unit tests isn’t always enough to prove that our program is working successfully. To show that all the parts of our program work with each other properly, communicating and transferring data between them correctly, we use **integration tests**. In this lesson, we'll focus on unit tests; however, when you start building larger programs, you will want to use **integration tests** as well.<br>\n",
    "\n",
    "#### Unit testing tools\n",
    "To install `pytest`, run `pip install -U pytest` in your terminal. You can see more information on getting started [here](https://docs.pytest.org/en/latest/getting-started.html).\n",
    "* Create a test file starting with test_.\n",
    "* Define unit test functions that start with test_ inside the test file.\n",
    "* Enter pytest into your terminal in the directory of your test file and it detects these tests for you.\n",
    "\n",
    "`test_` is the default; if you wish to change this, you can learn how with this `pytest` [Examples and Customizations link](https://docs.pytest.org/en/latest/example/index.html?highlight=customize).<br>\n",
    "\n",
    "In the test output, periods represent successful unit tests and Fs represent failed unit tests. Since all you see is which test functions failed, it's wise to have only one `assert` statement per test. Otherwise, you won't know exactly how many tests failed or which tests failed.<br>\n",
    "\n",
    "Your test won't be stopped by failed `assert` statements, but it will stop if you have syntax errors.\n",
    "\n",
    "### Integration Tests\n",
    "Integration testing exercises two or more parts of an application at once, including the interactions between the parts, to determine if they function as intended. This type of testing identifies defects in the interfaces between disparate parts of a codebase as they invoke each other and pass data between themselves.\n",
    "\n",
    "\n",
    "To learn more about integration testing and how integration tests relate to unit tests, see [Integration Testing](https://www.fullstackpython.com/integration-testing.html). That article contains other very useful links as well.\n",
    "\n",
    "### Test-driven development and data science\n",
    "* Test-driven development: Writing tests before you write the code that’s being tested. Your test fails at first, and you know you’ve finished implementing a task when the test passes.\n",
    "* Tests can check for different scenarios and edge cases before you even start to write your function. When start implementing your function, you can run the test to get immediate feedback on whether it works or not as you tweak your function.\n",
    "* When refactoring or adding to your code, tests help you rest assured that the rest of your code didn't break while you were making those changes. Tests also helps ensure that your function behavior is repeatable, regardless of external parameters such as hardware and time.\n",
    "\n",
    "> Uncle Bob's rules about TDD (Test Driven Development)Ç\n",
    "1. A test driven developer does not write a single line of code until he has written a faileing unit test. No production code can be shiped until there is a failing unit test.\n",
    "2. You do not write more unit tests than it's sufficient to fail. Not compiling is failing.\n",
    "3. You do not write more production code than it is sufficient to passa a failing test.\n",
    "\n",
    "> Jim Coplien advises\n",
    "1. Use TDD in a defined and consolidates architecture\n",
    "2. Use TDD based on a defined problem and as a mean to achieve the solution for it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### \"Problems\" in applying *DD to Data Science & Big Data\n",
    "\n",
    "##### Use of Notebooks and Web GUIs\n",
    "\n",
    "1. Notebooks encourage flat structure, resulting in disorganised code\n",
    "2. They are powerful interactive tools, but not powerful code editors; code inspections, refactoring tools, etc are weak\n",
    "3. They encourage manual testing\n",
    "4. They cannot be tracked by git (they are stored as JSON, not code)\n",
    "5. Your output, your business value, has a dependency on a software environment\n",
    "\n",
    "Always plan to deliver something that is independent of your own knowledge and toolchain.\n",
    "\n",
    "##### Model Performance\n",
    "we have a use case and that use case can determine a few desirable score-thresholds along with a minimum level of acceptable performance.\n",
    "\n",
    "> Then you can write a test that at thresholds A, B and C say, the models precision say, is greater than the acceptable levels of A', B' and C' say.\n",
    "\n",
    "##### Speed Tests and Slow Jobs\n",
    "We have some \"acceptable limit\" on how long the jobs should take. Ideally have a good **CI pipeline** that automatically runs nightly tests on your master branch on a realistic cluster.<br>\n",
    "\n",
    "Another trick which can work well for jobs that are known to downscale (i.e. work on less nodes but just slower) is to make your dev cluster much larger than your prod cluster so you can speed up your development cycle.\n",
    "\n",
    "##### Resource Problems\n",
    "This is again a real problem in Big Data. It's hard to write a test for out of memory errors, or disk space errors. The solution is again similar to the above, setup a good **CI pipeline** to automate the running of your jobs *every night* and *before release*.\n",
    "\n",
    "> \"you don't go fast by rushing you go fast by being deliberate\" Uncle Bob\n",
    "\n",
    "#### More on the topic: Testing\n",
    "\n",
    "Test-driven development (TDD) for data science is relatively new and is experiencing a lot of experimentation and breakthroughs. You can learn more about it by exploring the following resources.\n",
    "\n",
    "* [Data Science TDD](https://www.linkedin.com/pulse/data-science-test-driven-development-sam-savage/): Blog post about how to apply the principles of TDD to data science.\n",
    "* [TDD is Essential for Good Data Science Here's Why](https://medium.com/@karijdempsey/test-driven-development-is-essential-for-good-data-science-heres-why-db7975a03a44): Explanation of why TDD is important to improve data science.\n",
    "* [Testing Your Code](https://docs.python-guide.org/writing/tests/): Some general rules and practices for using TDD in Python.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n",
    "Logging is the process of recording messages to describe events that have occurred while running your software. Let's take a look at a few examples, and learn tips for writing good log messages.\n",
    "\n",
    "### Tips\n",
    "\n",
    "#### Be professional and clear\n",
    "\n",
    "```\n",
    "Bad: Hmmm... this isn't working???\n",
    "Bad: idk.... :(\n",
    "Good: Couldn't parse file.\n",
    "```\n",
    "#### Be concise and use normal capitalization\n",
    "```\n",
    "Bad: Start Product Recommendation Process\n",
    "Bad: We have completed the steps necessary and will now proceed with the recommendation process for the records in our product database.\n",
    "Good: Generating product recommendations.\n",
    "```\n",
    "#### Choose the appropriate level for logging\n",
    "\n",
    "* **Debug**: Use this level for anything that happens in the program.\n",
    "* **Error**: Use this level to record any error that occurs.\n",
    "* **Info**: Use this level to record all actions that are user-driven or system-specific, such as regularly scheduled operations.\n",
    "\n",
    "#### Provide any useful information\n",
    "```\n",
    "Bad: Failed to read location data\n",
    "Good: Failed to read location data: store_id 8324971\n",
    "```\n",
    "\n",
    "### Logging in Python\n",
    "It is easy to add logging to Python code. The first step is importing the logging module at the top of your code.\n",
    "```python\n",
    "import logging\n",
    "```\n",
    "After that, you can add messages to a logger.\n",
    "```python\n",
    "logging.debug('This is a debug message') # Anything that happens in the program\n",
    "logging.info('This is an info message') # To record all actions that are user-driven or system specific such as regularly scheduled operations\n",
    "logging.error('This is an error message') # To record any error that occurs\n",
    "```\n",
    "Notice that the statement for a log message is `logging.LEVEL` where *LEVEL* corresponds to the level of the log message *(debug, info, error)*, and then the message itself is passed as a parameter. There are additional levels of logging, but they are beyond the scope of this lesson.<br>\n",
    "\n",
    "Of the three levels discussed, only the error messages will be logged by default so the output of these statements is\n",
    "\n",
    "```\n",
    "ERROR:root:This is an error message\n",
    "```\n",
    "The \"root\" in the output indicates that the default logger is being used. In order to log info and debug messages, the default level needs to be changed.\n",
    "\n",
    "### Recap\n",
    "\n",
    "![logging](images/logging.PNG)\n",
    "\n",
    "![logging_level](images/logging_level.PNG)\n",
    "\n",
    "### Additional Information\n",
    "For more information on logging in Python, check out this [blog post](https://realpython.com/python-logging/)\n",
    "\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "logging.debug('able to read file:'+winequality-red.csv) \n",
    "df.columns = [label.replace(' ', '_') for label in df.columns]\n",
    "logging.debug('updated column headers by replacing ' ' with '_')\n",
    "def numeric_to_buckets(df, column_name):\n",
    "    median = df[column_name].median()\n",
    "    logging.info('computed median:'+median)\n",
    "    for i, val in enumerate(df[column_name]):\n",
    "        if val >= median:\n",
    "            logging.debug('found val >= median for val:'+val )\n",
    "            df.loc[i, column_name] = 'high'\n",
    "        else:\n",
    "            df.loc[i, column_name] = 'low' \n",
    "for feature in df.columns[:-1]:\n",
    "    numeric_to_buckets(df, feature)\n",
    "    print(df.groupby(feature).quality.mean(), '\\n')\n",
    "logging.info('done bucketing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Reviews\n",
    "Code reviews benefit everyone in a team to promote best programming practices and prepare code for production.\n",
    "\n",
    "They are especially helpful in:\n",
    "\n",
    "* Catching errors\n",
    "* Ensuring readability of your code\n",
    "* Checking to be sure standards are being met.\n",
    "* Sharing knowledge within your team\n",
    "\n",
    "Let's go over what to look for in a code review and some tips on how to conduct one.\n",
    "\n",
    "* [Code reviews](https://github.com/lyst/MakingLyst/tree/master/code-reviews): Check out the guidelines for conducting code reviews at Lyst.\n",
    "* [Code review best practices](https://www.kevinlondon.com/2015/05/05/code-review-best-practices.html): This is a blog post about general best practices, what to look for, and how to approach code reviews.\n",
    "\n",
    "### Reviewing code\n",
    "#### Know what you need to review\n",
    "Because getting PRs merged quickly is so important you need to stay on top of the changes people want your input on. You can use tools like Trailer.app or even simply searches in GitHub using \"involves:<YOUR USERNAME>\" to find PRs relevant to you.\n",
    "\n",
    "#### Respond quickly\n",
    "Tolerate being interrupt driven. You need focussed time to your other work done but PRs are time sensitive because they block other people. You shouldn't put off code review for more than a few hours. Never more than a day.\n",
    "\n",
    "#### Prioritise code review highly\n",
    "It's one of the most important things you can work on. The only things that should come ahead of it are time critical work such as fixing availability problems or dealing with high priority requests from customers. This means you should expect to spend some time every day doing reviews and that you will probably need to spend 2-3 sessions per day replying to PRs and reading other people's code.\n",
    "\n",
    "#### Be thorough\n",
    "Reviewing code is hard and error prone. It is our last line of defence against downtime and tech debt. You must pay attention, ask questions and not +1 lightly. Sometimes you will slip and miss something or only notice late in the review process. This not great but it is forgiven. Own up to it and move on. Confused about a bit of code? Ask what it does - *there are no stupid questions*.\n",
    "\n",
    "#### Don't block progress\n",
    "While code reviews need to be done thoughtfully and thoroughly we also need to avoid blocking progress. This means you should help people with solutions, not only identify problems. Often it might be faster to go and pair with someone for a bit to get their code tidied up instead of going back and forth on GitHub about it. Be aware that some test suites takes some time to run and it may make more sense for some fixes to be made in subsequent PRs instead of being added to this one.\n",
    "\n",
    "### Things to look for\n",
    "#### Clarity\n",
    "Things should be named well and should be easy to follow when reading. The code should attempt to be self documenting.\n",
    "\n",
    "#### Correctness\n",
    "There must be unit tests. They should test the edge cases. The code should behave as the submitter described. The code should use other APIs correctly.\n",
    "\n",
    "#### Security\n",
    "The design should not introduce any security problems such as potential denial of service attacks or unintended information disclosures. In particular we should be aware of potential CSRF and XSS attacks.\n",
    "\n",
    "#### Performance\n",
    "The code should perform within our targets for a particular area. It should not use obviously suboptimal algorithms. However optimisation is usually best left to later. Except when it can also improve other areas at the same time. Simpler code is often faster.\n",
    "<br>\n",
    "\n",
    "### Questions to ask yourself when conducting a code review\n",
    "Let's look over some of the questions we might ask ourselves while reviewing code. These are drawn from the concepts we've covered in these last two lessons.\n",
    "\n",
    "#### Is the code clean and modular?\n",
    "* Can I understand the code easily?\n",
    "* Does it use meaningful names and whitespace?\n",
    "* Is there duplicated code? (Three strikes rule)\n",
    "* Can I provide another layer of abstraction?\n",
    "* Is each function and module necessary?\n",
    "* Is each function or module too long?\n",
    "\n",
    "#### Is the code efficient?\n",
    "* Are there loops or other steps I can vectorize?\n",
    "* Can I use better data structures to optimize any steps?\n",
    "* Can I shorten the number of calculations needed for any steps?\n",
    "* Can I use generators or multiprocessing to optimize any steps?\n",
    "\n",
    "#### Is the documentation effective?\n",
    "* Are inline comments concise and meaningful?\n",
    "* Is there complex code that's missing documentation?\n",
    "* Do functions use effective docstrings?\n",
    "* Is the necessary project documentation provided?\n",
    "\n",
    "#### Is the code well tested?\n",
    "* Does the code have test coverage?\n",
    "* Do tests check for interesting cases?\n",
    "* Are the tests readable?\n",
    "* Can the tests be made more efficient?\n",
    "\n",
    "#### Is the logging effective?\n",
    "* Are log messages clear, concise, and professional?\n",
    "* Do they include all relevant and useful information?\n",
    "* Do they use the appropriate logging level?\n",
    "\n",
    "### Tips for conducting a code review\n",
    "The goal of code review isn't to make all code follow your personal preferences, but to ensure it meets a standard of quality for the whole team.\n",
    "\n",
    "#### Use a code linter\n",
    "This isn't really a tip for code review, but it can save you lots of time in a code review. Using a Python code linter like [pylint](https://www.pylint.org/) can automatically check for coding standards and PEP 8 guidelines for you. It's also a good idea to agree on a style guide as a team to handle disagreements on code style, whether that's an existing style guide or one you create together incrementally as a team.\n",
    "\n",
    "#### Explain issues and make suggestions\n",
    "*Suggest* changes to improve it. They will be much more receptive to your feedback if they understand your thought process and are accepting recommendations, rather than following commands.\n",
    "```\n",
    "BAD: Make model evaluation code its own module - too repetitive.\n",
    "\n",
    "BETTER: Make the model evaluation code its own module. This will simplify models.py to be less repetitive and focus primarily on building models.\n",
    "\n",
    "GOOD: How about we consider making the model evaluation code its own module? This would simplify models.py to only include code for building models. Organizing these evaluations methods into separate functions would also allow us to reuse them with different models without repeating code.\n",
    "```\n",
    "#### Keep your comments objective\n",
    "Try to avoid using the words \"I\" and \"you\" in your comments. You want to avoid comments that sound personal to bring the attention of the review to the code and not to themselves.\n",
    "```\n",
    "BAD: I wouldn't groupby genre twice like you did here... Just compute it once and use that for your aggregations.\n",
    "\n",
    "BAD: You create this groupby dataframe twice here. Just compute it once, save it as groupby_genre and then use that to get your average prices and views.\n",
    "\n",
    "GOOD: Can we group by genre at the beginning of the function and then save that as a groupby object? We could then reference that object to get the average prices and views without computing groupby twice.\n",
    "```\n",
    "#### Provide code examples\n",
    "When providing a code review, you can save the author time and make it easy for them to act on your feedback by writing out your code suggestions.It can also just be much quicker for you to demonstrate concepts through code rather than explanations.\n",
    "<br>\n",
    "Let's say you were reviewing code that included the following lines:\n",
    "```python\n",
    "first_names = []\n",
    "last_names = []\n",
    "\n",
    "for name in enumerate(df.name):\n",
    "    first, last = name.split(' ')\n",
    "    first_names.append(first)\n",
    "    last_names.append(last)\n",
    "\n",
    "df['first_name'] = first_names\n",
    "df['last_names'] = last_names\n",
    "```\n",
    "```\n",
    "BAD: You can do this all in one step by using the pandas str.split method.\n",
    "\n",
    "GOOD: We can actually simplify this step to the line below using the pandas str.split method. Found this on this stack overflow post: https://stackoverflow.com/questions/14745022/how-to-split-a-column-into-two-columns\n",
    "```\n",
    "```python\n",
    "df['first_name'], df['last_name'] = df['name'].str.split(' ', 1).str\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
